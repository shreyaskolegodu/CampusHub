import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import scipy.stats as stats
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
import warnings
warnings.filterwarnings('ignore')

df = sns.load_dataset('diamonds')

print("=== Dataset Overview and Feature Identification ===")
print("Column names and data types:")
print(df.dtypes)
print(f"\nDataset shape: {df.shape}")
print(f"Rows: {df.shape[0]}, Columns: {df.shape[1]}")

if 'index' in df.columns or df.index.name is not None:
    print("Index column exists and should be removed as it doesn't provide meaningful information for analysis")
    df = df.reset_index(drop=True)

print("\nFirst five rows:")
print(df.head())
print("\nLast five rows:")
print(df.tail())

print("\n=== Data Quality Insights ===")
print("Missing values per column:")
print(df.isnull().sum())
print(f"Duplicate records: {df.duplicated().sum()}")

zero_dimensions = df[(df['x'] <= 0) | (df['y'] <= 0) | (df['z'] <= 0)]
print(f"Diamonds with zero or negative dimensions: {len(zero_dimensions)}")

df_clean = df[(df['x'] > 0) & (df['y'] > 0) & (df['z'] > 0)].copy()
print(f"Original dataset shape: {df.shape}")
print(f"Cleaned dataset shape: {df_clean.shape}")

print("\n=== Descriptive Statistical Summary ===")
numeric_cols = ['price', 'carat', 'depth', 'table', 'x', 'y', 'z']
stats_summary = df_clean[numeric_cols].describe()
stats_summary.loc['range'] = stats_summary.loc['max'] - stats_summary.loc['min']
stats_summary.loc['median'] = df_clean[numeric_cols].median()
print(stats_summary)

print("\nBest measure of central tendency:")
for col in numeric_cols:
    skewness = df_clean[col].skew()
    if abs(skewness) > 1:
        best_measure = 'median'
    else:
        best_measure = 'mean'
    print(f"{col}: {best_measure} is better (skewness: {skewness:.2f})")

price_skew = df_clean['price'].skew()
print(f"\nPrice distribution skewness: {price_skew:.2f}")
if abs(price_skew) > 0.5:
    print("Price distribution is skewed")
else:
    print("Price distribution is approximately symmetrical")

print("\n=== Visual Data Exploration ===")
plt.figure(figsize=(15, 5))

plt.subplot(1, 2, 1)
plt.hist(df_clean['price'], bins=50, edgecolor='black', alpha=0.7, color='skyblue')
plt.title('Distribution of Diamond Prices')
plt.xlabel('Price (USD)')
plt.ylabel('Frequency')

plt.subplot(1, 2, 2)
carat_bins = np.arange(0, df_clean['carat'].max() + 0.1, 0.1)
plt.hist(df_clean['carat'], bins=carat_bins, edgecolor='black', alpha=0.7, color='lightgreen')
plt.title('Distribution of Diamond Carat Weights')
plt.xlabel('Carat')
plt.ylabel('Frequency')
plt.tight_layout()
plt.show()

plt.figure(figsize=(12, 6))
sns.boxplot(data=df_clean, x='cut', y='price', palette='viridis')
plt.title('Diamond Prices by Cut Quality')
plt.xlabel('Cut Quality')
plt.ylabel('Price (USD)')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

print("\n=== Outlier Detection and Treatment ===")
def detect_outliers_iqr(data):
    Q1 = data.quantile(0.25)
    Q3 = data.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = (data < lower_bound) | (data > upper_bound)
    return outliers

outlier_cols = ['price', 'carat', 'depth', 'table']
outliers_summary = {}

print("Number of outliers detected:")
for col in outlier_cols:
    outliers = detect_outliers_iqr(df_clean[col])
    outliers_summary[col] = outliers.sum()
    print(f"{col}: {outliers.sum()} outliers")

plt.figure(figsize=(15, 6))

plt.subplot(1, 2, 1)
sns.boxplot(data=df_clean[['price', 'carat']])
plt.title('Boxplot of Price and Carat (Before Outlier Removal)')
plt.xticks(rotation=45)

df_no_outliers = df_clean.copy()
for col in ['price', 'carat']:
    outliers = detect_outliers_iqr(df_clean[col])
    df_no_outliers = df_no_outliers[~outliers]

plt.subplot(1, 2, 2)
sns.boxplot(data=df_no_outliers[['price', 'carat']])
plt.title('Boxplot of Price and Carat (After Outlier Removal)')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

print(f"Dataset shape before outlier removal: {df_clean.shape}")
print(f"Dataset shape after outlier removal: {df_no_outliers.shape}")

print("\n=== Normality Check using Q-Q Plot ===")
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

dimensions = ['x', 'y', 'z']
for i, dim in enumerate(dimensions):
    stats.probplot(df_clean[dim], dist="norm", plot=axes[i])
    axes[i].set_title(f'Q-Q Plot for {dim.upper()}')

plt.tight_layout()
plt.show()

print("Normality assessment:")
for dim in dimensions:
    stat, p_value = stats.normaltest(df_clean[dim])
    print(f"{dim.upper()}: p-value = {p_value:.4f} - {'Normal' if p_value > 0.05 else 'Not Normal'}")

print("\n=== Correlation Mapping ===")
plt.figure(figsize=(10, 8))
numeric_df = df_clean.select_dtypes(include=[np.number])
correlation_matrix = numeric_df.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, square=True)
plt.title('Correlation Heatmap of Diamond Characteristics')
plt.tight_layout()
plt.show()

price_correlations = correlation_matrix['price'].drop('price')
strongest_corr_var = price_correlations.idxmax()
strongest_corr_value = price_correlations.max()
weakest_corr_var = price_correlations.idxmin()
weakest_corr_value = price_correlations.min()

print(f"Strongest correlation with price: {strongest_corr_var} ({strongest_corr_value:.3f})")
print(f"Weakest correlation with price: {weakest_corr_var} ({weakest_corr_value:.3f})")

print("\n=== Confidence Interval for Diamond Carat Weight ===")
carat_data = df_clean['carat']
carat_mean = carat_data.mean()
carat_std = carat_data.std()
n = len(carat_data)
confidence_level = 0.95

t_critical = stats.t.ppf((1 + confidence_level) / 2, n - 1)
margin_of_error = t_critical * (carat_std / np.sqrt(n))
ci_lower = carat_mean - margin_of_error
ci_upper = carat_mean + margin_of_error

print(f"95% Confidence Interval for Carat Weight: ({ci_lower:.3f}, {ci_upper:.3f})")
print(f"This means we are 95% confident that the true population mean carat weight falls between {ci_lower:.3f} and {ci_upper:.3f} carats")

print("\n=== Margin of Error and Confidence Levels ===")
price_data = df_clean['price']
price_mean = price_data.mean()
price_std = price_data.std()

confidence_levels = [0.90, 0.95, 0.99]
print("Margin of Error for Price at different confidence levels:")
for cl in confidence_levels:
    t_critical = stats.t.ppf((1 + cl) / 2, n - 1)
    margin_error = t_critical * (price_std / np.sqrt(n))
    print(f"{int(cl*100)}% Confidence Level: Margin of Error = ${margin_error:.2f}")

print("\n=== Cut Quality and Price Difference ===")
ideal_prices = df_clean[df_clean['cut'] == 'Ideal']['price']
fair_prices = df_clean[df_clean['cut'] == 'Fair']['price']

print(f"Ideal cut diamonds: {len(ideal_prices)} samples")
print(f"Fair cut diamonds: {len(fair_prices)} samples")

print("\nHypotheses:")
print("H₀ (Null): There is no significant difference in average price between Ideal and Fair cut diamonds")
print("H₁ (Alternative): There is a significant difference in average price between Ideal and Fair cut diamonds")

t_stat, p_value = stats.ttest_ind(ideal_prices, fair_prices, equal_var=False)
print(f"\nT-test results:")
print(f"T-statistic: {t_stat:.4f}")
print(f"P-value: {p_value:.4f}")

alpha = 0.05
if p_value < alpha:
    print("Conclusion: Reject the null hypothesis - There is a significant difference in prices")
else:
    print("Conclusion: Fail to reject the null hypothesis - No significant difference in prices")

print(f"Average price - Ideal cut: ${ideal_prices.mean():.2f}")
print(f"Average price - Fair cut: ${fair_prices.mean():.2f}")

print("\n=== Relationship between Carat and Price ===")
pearson_corr, p_val = stats.pearsonr(df_clean['carat'], df_clean['price'])
print(f"Pearson correlation coefficient: {pearson_corr:.3f}")

if abs(pearson_corr) >= 0.7:
    strength = "strong"
elif abs(pearson_corr) >= 0.3:
    strength = "moderate"
else:
    strength = "weak"

direction = "positive" if pearson_corr > 0 else "negative"
print(f"This indicates a {strength} {direction} relationship between carat and price")

plt.figure(figsize=(10, 6))
plt.scatter(df_clean['carat'], df_clean['price'], alpha=0.5, s=1)
plt.xlabel('Carat Weight')
plt.ylabel('Price (USD)')
plt.title('Relationship between Carat Weight and Price')

z = np.polyfit(df_clean['carat'], df_clean['price'], 1)
p = np.poly1d(z)
plt.plot(df_clean['carat'], p(df_clean['carat']), "r--", alpha=0.8)

plt.tight_layout()
plt.show()

print("\n=== Regression Model for Price Prediction ===")
X = df_clean['carat'].values.reshape(-1, 1)
y = df_clean['price'].values

model = LinearRegression()
model.fit(X, y)

y_pred = model.predict(X)
r2 = r2_score(y, y_pred)

intercept = model.intercept_
slope = model.coef_[0]

print(f"Regression Equation: Price = {intercept:.2f} + {slope:.2f} × Carat")
print(f"Slope interpretation: On average, each additional carat increases the price by ${slope:.2f}")
print(f"R² score: {r2:.4f}")
print(f"This means the model explains {r2*100:.2f}% of the variance in diamond prices")

plt.figure(figsize=(10, 6))
plt.scatter(df_clean['carat'], df_clean['price'], alpha=0.5, s=1, label='Actual Data')
plt.plot(df_clean['carat'], y_pred, color='red', linewidth=2, label='Regression Line')
plt.xlabel('Carat Weight')
plt.ylabel('Price (USD)')
plt.title('Linear Regression: Carat vs Price')
plt.legend()
plt.tight_layout()
plt.show()

print("\n=== Analysis Complete ===")